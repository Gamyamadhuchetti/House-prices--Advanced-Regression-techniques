Creating app with STREAMLIT

Streamlit is more than just a way to make data apps, it’s also a community of creators that share their apps and ideas and help each other make their work better. 

The first step is to create a new Python script. Let's call it uber_pickups.py.

Open uber_pickups.py in your favorite IDE or text editor, then add these lines:

import streamlit as st
import pandas as pd
import numpy as np

Every good app has a title, so let's add one:

st.title('Uber pickups in NYC')

Now it's time to run Streamlit from the command line:

streamlit run uber_pickups.py

Running a Streamlit app is no different than any other Python script. Whenever we need to view the app, we need to use this command.


We can also pass a URL to streamlit run? This is great when combined with Github Gists. 

For example:

$ streamlit run https://raw.githubusercontent.com/streamlit/demo-uber-nyc-pickups/master/streamlit_app.py

As usual, the app should automatically open in a new tab in an browser.

Now that we have an app, the next thing we need to do is fetch the Uber dataset for pickups and drop-offs in New York City.

Let's start by writing a function to load the data. Add the code that's needed to be added to the script:

DATE_COLUMN = 'date/time'
DATA_URL = ('https://s3-us-west-2.amazonaws.com/'
         'streamlit-demo-data/uber-raw-data-sep14.csv.gz')

def load_data(nrows):
    data = pd.read_csv(DATA_URL, nrows=nrows)
    lowercase = lambda x: str(x).lower()
    data.rename(lowercase, axis='columns', inplace=True)
    data[DATE_COLUMN] = pd.to_datetime(data[DATE_COLUMN])
    return data

 load_data is a plain old function that downloads some data, puts it in a Pandas dataframe, and converts the date column from text to datetime. 
The function accepts a single parameter (nrows), which specifies the number of rows that you want to load into the dataframe.

Now let's test the function and review the output.

# Create a text element and let the reader know the data is loading.
data_load_state = st.text('Loading data...')
# Load 10,000 rows of data into the dataframe.
data = load_data(10000)
# Notify the reader that the data was successfully loaded.
data_load_state.text('Loading data...done!')

we will see a few buttons in the upper-right corner of the app asking if we like to rerun the app. 
Choose Always rerun, and we see the changes automatically each time we save.

It turns out that it takes a long time to download data, and load 10,000 lines into a dataframe. 
Converting the date column into datetime isn’t a quick job either. 
we don’t want to reload the data each time the app is updated – luckily Streamlit allows us to cache the data.




Effortless caching
Try adding @st.cache before the load_data declaration:

@st.cache
def load_data(nrows):

Then save the script, and Streamlit will automatically rerun the app. 
Since this is the first time running the script with @st.cache, we won't see anything change. 
Let’s tweak our file a little bit more so that we can see the power of caching.

Replace the line data_load_state.text with this:

data_load_state.text("Done! (using st.cache)")

Now save. 

we will see that the line we added appeared.
 And it only takes one line of code to activate it.



Let's take a few minutes to discuss how @st.cache actually works.

When we mark a function with Streamlit’s cache annotation, it tells Streamlit that whenever the function is called that it should check three things:

1.The actual bytecode that makes up the body of the function

2. Code, variables, and files that the function depends on

3. The input parameters that you called the function with

If this is the first time Streamlit has seen these items, with these exact values, and in this exact combination,
 it runs the function and stores the result in a local cache. 
The next time the function is called, if the three values haven't changed, then Streamlit knows it can skip executing the function altogether. 
Instead, it reads the output from the local cache and passes it on to the caller.

Streamlit will only check for changes within the current working directory. 
If we upgrade a Python library, Streamlit's cache will only notice this if that library is installed inside the working directory.

If the function is not deterministic (that is, its output depends on random numbers), or if it pulls data from an external time-varying source
 (for example, a live stock market ticker service) the cached value will be none-the-wiser.

Lastly, we should not mutate the output of a cached function since cached values are stored by reference (for performance reasons and to be able to support libraries such as TensorFlow). 

Note that, here, Streamlit is smart enough to detect these mutations and show a loud warning explaining how to fix the problem.


While these limitations are important to keep in mind, they tend not to be an issue a surprising amount of the time. Those times, this cache is really transformational.

Whenever we have a long-running computation in our code, consider refactoring it so we can use @st.cache.


Inspect the raw data:
It's always a good idea to take a look at the raw data we are working with before we start working with it. 
Let's add a subheader and a printout of the raw data to the app:

st.subheader('Raw data')
st.write(data)

 st.write will render almost anything we pass to it. 
In this case, we are passing in a dataframe and it's rendering as an interactive table.

st.write tries to do the right thing based on the data type of the input. 
If it isn't doing what we expect we can use a specialized command like st.dataframe instead. 


Draw a histogram:
Now that you've had a chance to take a look at the dataset and observe what's available, let's take things a step further and draw a histogram to see what Uber's busiest hours 
are in New York City.

To start, let's add a subheader just below the raw data section:

st.subheader('Number of pickups by hour')

Use NumPy to generate a histogram that breaks down pickup times binned by hour:

hist_values = np.histogram(
    data[DATE_COLUMN].dt.hour, bins=24, range=(0,24))[0]

Now, let's use Streamlit's st.bar_chart() method to draw this histogram.

st.bar_chart(hist_values)

Save script. 
This histogram should show up in app right away. 
After a quick review, it looks like the busiest time is 17:00 (5 P.M.).

To draw this diagram we used Streamlit's native bar_chart() method, but it's important to know that Streamlit supports more complex charting libraries like Altair,
 Bokeh, Plotly, Matplotlib and more. For a full list, see supported charting libraries.

Plot data on a map:
Using a histogram with Uber's dataset helped us determine what the busiest times are for pickups, but what if we wanted to 
figure out where pickups were concentrated throughout the city.

 While we could use a bar chart to show this data, it wouldn't be easy to interpret unless we were intimately familiar with latitudinal and longitudinal coordinates in the city.
 To show pickup concentration, let's use Streamlit st.map() function to overlay the data on a map of New York City.

Add a subheader for the section:

st.subheader('Map of all pickups')

Use the st.map() function to plot the data:

st.map(data)

Save script.
 The map is fully interactive. Give it a try by panning or zooming in a bit.

After drawing histogram, we have determined that the busiest hour for Uber pickups was 17:00. 
Let's redraw the map to show the concentration of pickups at 17:00.

Locate the following code snippet:

st.subheader('Map of all pickups')
st.map(data)

Replace it with:

hour_to_filter = 17
filtered_data = data[data[DATE_COLUMN].dt.hour == hour_to_filter]
st.subheader(f'Map of all pickups at {hour_to_filter}:00')
st.map(filtered_data)

we will see the data update instantly.

To draw this map we used the st.map function that's built into Streamlit, but if you'd like to visualize complex map data, we encourage you to take a look at the st.pydeck_chart.

Filter results with a slider
Previously,  when we drew the map, the time used to filter results was hardcoded into the script, but what if we wanted to let a reader dynamically filter the data in real time? 

Using Streamlit's widgets you can. Let's add a slider to the app with the st.slider() method.

Locate hour_to_filter and replace it with this code snippet:

hour_to_filter = st.slider('hour', 0, 23, 17)  # min: 0h, max: 23h, default: 17h

Use the slider and watch the map update in real time.

Use a button to toggle data
Sliders are just one way to dynamically change the composition of app.
 Let's use the st.checkbox function to add a checkbox to your app. 
We'll use this checkbox to show/hide the raw data table at the top of your app.

Locate these lines:

st.subheader('Raw data')
st.write(data)

Replace these lines with the following code:

if st.checkbox('Show raw data'):
    st.subheader('Raw data')
    st.write(data)


Let's put it all together
 Here's the complete script for our interactive app.

If we've skipped ahead, after we created script, the command to run Streamlit is streamlit run [app name].

import streamlit as st
import pandas as pd
import numpy as np

st.title('Uber pickups in NYC')

DATE_COLUMN = 'date/time'
DATA_URL = ('https://s3-us-west-2.amazonaws.com/'
            'streamlit-demo-data/uber-raw-data-sep14.csv.gz')

@st.cache
def load_data(nrows):
    data = pd.read_csv(DATA_URL, nrows=nrows)
    lowercase = lambda x: str(x).lower()
    data.rename(lowercase, axis='columns', inplace=True)
    data[DATE_COLUMN] = pd.to_datetime(data[DATE_COLUMN])
    return data

data_load_state = st.text('Loading data...')
data = load_data(10000)
data_load_state.text("Done! (using st.cache)")

if st.checkbox('Show raw data'):
    st.subheader('Raw data')
    st.write(data)

st.subheader('Number of pickups by hour')
hist_values = np.histogram(data[DATE_COLUMN].dt.hour, bins=24, range=(0,24))[0]
st.bar_chart(hist_values)

# Some number in the range 0-23
hour_to_filter = st.slider('hour', 0, 23, 17)
filtered_data = data[data[DATE_COLUMN].dt.hour == hour_to_filter]

st.subheader('Map of all pickups at %s:00' % hour_to_filter)
st.map(filtered_data)

Share your app
After you’ve built a Streamlit app, it's time to share it! To show it off to the world you can use Streamlit Cloud to deploy, manage, and share your app for free. 
Streamlit Cloud is currently invitation only, so please request an invite and we'll get you one soon!

It works in 3 simple steps:

Put your app in a public Github repo (and make sure it has a requirements.txt!)
Sign into share.streamlit.io
Click 'Deploy an app' and then paste in your GitHub URL
That's it! 🎈You now have a publicly deployed app that you can share with the world. Click to learn more about how to use Streamlit Cloud. If you're looking for private sharing for your team, check out the Team and Enterprise tiers.























